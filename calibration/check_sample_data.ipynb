{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2059941d-b1ea-4a49-934e-f9c8d99627f4",
   "metadata": {},
   "source": [
    "# Load the movement dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a74b4f-0365-409a-9811-f558edb72699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from calibration_utils import (\n",
    "    binning_based_calibration,\n",
    "    plot_reliability_diagram,\n",
    ")\n",
    "\n",
    "from movement import sample_data\n",
    "from movement.filtering import rolling_filter, savgol_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c78b6f-98a8-4841-8185-da9df5aad825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DLC sample data\n",
    "filename = \"DLC_single-mouse_EPM.predictions.h5\"\n",
    "data = sample_data.fetch_dataset(filename)\n",
    "# Print dataset structure\n",
    "print(data)\n",
    "# Check available variables\n",
    "print(data.variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa891fdf-0b89-4fe0-ae22-b4256238aab7",
   "metadata": {},
   "source": [
    "## Extract confidencs scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618c0c53-b7a6-4b6e-beb2-49d63d1ab8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract confidence values\n",
    "confidence_values = data[\"confidence\"].values\n",
    "\n",
    "# check if all values are NaN\n",
    "print(\"Total NaN values:\", np.isnan(confidence_values).sum())\n",
    "print(\"Total confidence values:\", confidence_values.size)\n",
    "\n",
    "# Find frames that contain at least one non-NaN confidence score\n",
    "valid_confidence_frames = np.where(\n",
    "    ~np.isnan(confidence_values).any(axis=(1, 2))\n",
    ")[0]\n",
    "print(\"Frames with valid confidence scores:\", valid_confidence_frames)\n",
    "confidence_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e674d6a5-a24f-42d6-906f-ea7dd5e8ce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NaNs if any\n",
    "confidence_values = confidence_values[~np.isnan(confidence_values)]\n",
    "\n",
    "# Print summary statistics\n",
    "print(f\"Mean: {np.mean(confidence_values):.4f}\")\n",
    "print(f\"Median: {np.median(confidence_values):.4f}\")\n",
    "print(f\"Min: {np.min(confidence_values):.4f}\")\n",
    "print(f\"Max: {np.max(confidence_values):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf639b5-f633-4654-86a8-5245c4b1b162",
   "metadata": {},
   "source": [
    "## Plot the distribution of confidence scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ef5ded-fd93-4df0-91a4-7962f6cce496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract confidence scores from DLC dataset\n",
    "confidence_values = data[\"confidence\"].values.flatten()\n",
    "\n",
    "# Plot histogram to see distribution\n",
    "plt.hist(confidence_values, bins=20, edgecolor=\"black\")\n",
    "plt.xlabel(\"Confidence Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Confidence Scores (DLC Data)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a466cc1d-91bb-4900-bf64-c0d39f794ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 10  # Number of bins\n",
    "bin_edges = np.linspace(0, 1, num_bins + 1)  # Create bin edges\n",
    "bin_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ce8fd4-076a-4943-9118-9b7da2963ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_confidence, _ = np.histogram(confidence_values, bins=bin_edges)\n",
    "avg_confidence_scores = np.mean(binned_confidence)\n",
    "binned_confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702db60c-5991-4e08-be22-a24d87b8a56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(\n",
    "    bin_edges[:-1],\n",
    "    binned_confidence,\n",
    "    width=0.1,\n",
    "    edgecolor=\"black\",\n",
    "    align=\"edge\",\n",
    ")\n",
    "plt.xlabel(\"Confidence Score Bins\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Binned Confidence Scores\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d60eca2-bf7b-47ae-9247-a03dcfc21717",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = data[\"position\"].values  # Extract (x, y) coordinates\n",
    "confidences = data[\"confidence\"].values  # Extract confidence scores\n",
    "\n",
    "print(\"Position shape:\", positions.shape)\n",
    "print(\"Confidence shape:\", confidences.shape)\n",
    "print(\"Position shape:\", positions)\n",
    "print(\"Confidence shape:\", confidences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243ff41d-906b-40f7-bc22-efc7cdb65eee",
   "metadata": {},
   "source": [
    "## smoothing positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d886e47d-38de-480e-b3a9-47e9db28209d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set smoothing window size (0.1 seconds of frames)\n",
    "fps = data.attrs[\"fps\"]  # Get FPS from dataset attributes\n",
    "window = int(0.1 * fps)\n",
    "\n",
    "# Apply Rolling Median Filter\n",
    "smoothed_positions = rolling_filter(\n",
    "    data[\"position\"], window, statistic=\"median\"\n",
    ")\n",
    "\n",
    "# Apply Savitzky-Golay Filter\n",
    "smoothed_positions = savgol_filter(smoothed_positions, window)\n",
    "smoothed_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20288f0-2ce0-4178-9e37-1e98780aeb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute velocity (change in position)\n",
    "velocity = np.diff(smoothed_positions, axis=0)\n",
    "\n",
    "# Compute acceleration (change in velocity)\n",
    "acceleration = np.diff(velocity, axis=0)\n",
    "\n",
    "# Compute acceleration magnitude\n",
    "acceleration_magnitude = np.sqrt(np.sum(acceleration**2, axis=1))\n",
    "\n",
    "print(\"Acceleration Shape:\", acceleration.shape)\n",
    "print(\"Sample Acceleration Magnitude:\", acceleration_magnitude[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e941e6de-2b47-4d1d-9d8c-e8ff09e054b1",
   "metadata": {},
   "source": [
    "##  Identify Uncertain Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eccb352-a860-48e5-84f7-30b581072b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.percentile(acceleration_magnitude, 95)  # 95th percentile\n",
    "\n",
    "# Mark frames with high acceleration as \"uncertain\"\n",
    "uncertain_frames = acceleration_magnitude > threshold\n",
    "\n",
    "print(\"Number of Uncertain Frames:\", np.sum(uncertain_frames))\n",
    "uncertain_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a5c7bf-0782-4a04-a8e0-0d4a68ab6a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confidence Values Shape:\", confidence_values.shape)\n",
    "print(\"Uncertain Frames Shape:\", uncertain_frames.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407fbc3c-33af-4716-aa38-cbc0f574043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape confidence_values to match (frames, keypoints, individuals)\n",
    "num_frames = 18485  # From DLC dataset\n",
    "num_keypoints = 8  # From DLC dataset\n",
    "num_individuals = 1  # Only one tracked mouse\n",
    "\n",
    "confidence_values = confidence_values.reshape(\n",
    "    num_frames, num_keypoints, num_individuals\n",
    ")\n",
    "print(\"Reshaped Confidence Values Shape:\", confidence_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1763bd-c36c-440f-ba33-2538f673a4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert uncertain_frames to match confidence_values first dimension\n",
    "uncertain_confidences = confidence_values[uncertain_frames.nonzero()[0], :, :]\n",
    "\n",
    "# Print stats\n",
    "print(\n",
    "    f\"Mean Confidence of Uncertain Frames: \"\n",
    "    f\"{np.mean(uncertain_confidences):.4f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Median Confidence of Uncertain Frames:\"\n",
    "    f\"{np.median(uncertain_confidences):.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a60682a-c1ed-44ed-b922-55019dd372aa",
   "metadata": {},
   "source": [
    "## Plot histogram for overall confidence & uncertain confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617c91e7-9562-4114-800c-3134872a86da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bins (same as before)\n",
    "num_bins = 10\n",
    "bin_edges = np.linspace(0, 1, num_bins + 1)\n",
    "\n",
    "# Compute histogram for overall confidence & uncertain confidence\n",
    "overall_counts, _ = np.histogram(confidence_values.flatten(), bins=bin_edges)\n",
    "uncertain_counts, _ = np.histogram(\n",
    "    uncertain_confidences.flatten(), bins=bin_edges\n",
    ")\n",
    "\n",
    "# Normalize to probability distribution\n",
    "overall_prob = overall_counts / np.sum(overall_counts)\n",
    "uncertain_prob = uncertain_counts / np.sum(uncertain_counts)\n",
    "\n",
    "# Plot reliability diagram\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(bin_edges[:-1], overall_prob, label=\"All Frames\", marker=\"o\")\n",
    "plt.plot(\n",
    "    bin_edges[:-1],\n",
    "    uncertain_prob,\n",
    "    label=\"Uncertain Frames\",\n",
    "    marker=\"o\",\n",
    "    linestyle=\"dashed\",\n",
    "    color=\"red\",\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Confidence Score Bins\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.title(\"Reliability Diagram: Overall vs. Uncertain Frames\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d4ea85-00a7-4e23-99e9-bac484373c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage\n",
    "np.random.seed(42)  # For reproducibility\n",
    "confidences = np.random.rand(1000)  # Simulated confidence scores\n",
    "labels = (\n",
    "    confidences + np.random.normal(0, 0.1, 1000)\n",
    ") > 0.5  # Simulated correctness labels\n",
    "\n",
    "calibrated_confidences, bin_edges, bin_accuracies = binning_based_calibration(\n",
    "    confidences, labels\n",
    ")\n",
    "print(\"Original Confidence Mean:\", np.mean(confidences))\n",
    "print(\"Calibrated Confidence Mean:\", np.mean(calibrated_confidences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f1a21a-f99d-401e-ac60-64e119075b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Reliability Diagram\n",
    "plot_reliability_diagram(\n",
    "    confidences, calibrated_confidences, labels, bin_edges\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f99475-f5c7-438b-a81e-03460fd565ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and print ECE\n",
    "from calibration_utils import compute_ece\n",
    "\n",
    "ece_before, ece_after = compute_ece(\n",
    "    confidences, calibrated_confidences, labels, bin_edges\n",
    ")\n",
    "print(f\"Expected Calibration Error (ECE) Before Calibration: {ece_before:.4f}\")\n",
    "print(f\"Expected Calibration Error (ECE) After Calibration: {ece_after:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movement-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
