{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pupil tracking\n\nLook at eye movements and pupil diameter.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import sleap_io as sio\nimport xarray as xr\nfrom matplotlib import pyplot as plt\n\nimport movement.kinematics as kin\nfrom movement import sample_data\nfrom movement.filtering import rolling_filter\nfrom movement.plots import plot_centroid_trajectory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the data\nWe will use two datasets from the sample data module. These datasets involve\nrecordings of the eyes of mice placed on a rotating platform with different\nvisual stimuli. The ``uniform`` condition features a uniformly lit surround\nstimulus, whereas the ``black`` condition was acquired in the dark. These\ndatasets were tracked using DeepLabCut (DLC) and include four keypoints:\ntwo on either side of the pupil (``pupil-L`` and ``pupil-R``) and two on\neither side of the eye (``eye-L`` and ``eye-R``).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ds_black = sample_data.fetch_dataset(\n    \"DLC_rotating-mouse_eye-tracking_stim-black.predictions.h5\",\n    with_video=True,\n)\nds_uniform = sample_data.fetch_dataset(\n    \"DLC_rotating-mouse_eye-tracking_stim-uniform.predictions.h5\",\n    with_video=True,\n)\n# Save data in a dictionary.\nds_dict = {\"black\": ds_black, \"uniform\": ds_uniform}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Print the content of one of the datasets.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(ds_dict[\"black\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Explore the accompanying videos\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for ds_name, ds in ds_dict.items():\n    video = sio.load_video(ds.video_path)\n    # To avoid having to reload the video again we add it to ds as attribute\n    ds_dict[ds_name] = ds.assign_attrs({\"video\": video})\n    n_frames, height, width, channels = video.shape\n    print(f\"Dataset: {ds_name}\")\n    print(f\"Number of frames: {n_frames}\")\n    print(f\"Frame size: {width}x{height}\")\n    print(f\"Number of channels: {channels}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot first frame with keypoints\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(7.5, 4))\nfor i, (da_name, ds) in enumerate(ds_dict.items()):\n    ax[i].imshow(ds.video[0], cmap=\"gray\")  # plot first video frame\n    for keypoint in ds.keypoints.values:\n        x = ds.position.sel(time=0, space=\"x\", keypoints=keypoint)\n        y = ds.position.sel(time=0, space=\"y\", keypoints=keypoint)\n        ax[i].scatter(x, y, label=keypoint)  # plot keypoints\n    ax[i].legend()\n    ax[i].set_title(f\"{da_name} (First Frame)\")\n    ax[i].invert_yaxis()  # because the dataset was collected flipped\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pupil trajectory\nA quick plot of the trajectory of the centre of the pupil using the\n``plot_centroid_trajectory`` function from ``movement.plots``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "time_window = slice(1, 24)  # seconds\nposition_black = ds_black.position.sel(time=time_window)  # data array to plot\nfig, ax = plot_centroid_trajectory(\n    position_black, keypoints=[\"pupil-L\", \"pupil-R\"]\n)\nfig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pupil trajectories on top of video frame\nWe can look at pupil trajectories plotted on top of a video frame.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(11, 3))\nfor i, (ds_name, ds) in enumerate(ds_dict.items()):\n    ax[i].imshow(ds.video[100], cmap=\"gray\")  # Plot frame 100 as background\n    plot_centroid_trajectory(\n        ds.position.sel(time=time_window),  # Select time window\n        ax=ax[i],\n        keypoints=[\"pupil-L\", \"pupil-R\"],\n        alpha=0.5,\n        s=3,\n    )\n    ax[i].invert_yaxis()\n    ax[i].set_title(f\"Pupil Trajectory ({ds_name})\")\nfig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Keypoint positions over time\nFor the rest of this example we are only interested in the position data.\nFor convenience, We will combine the two position arrays into a single\narray with a new dimension called ``lighting``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "positions = xr.concat([ds_black.position, ds_uniform.position], \"lighting\")\npositions.coords[\"lighting\"] = [\"black\", \"uniform\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define plotting parameters for reuse.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot_params = {\n    \"x\": \"time\",\n    \"hue\": \"keypoints\",\n    \"col\": \"space\",\n    \"row\": \"lighting\",\n    \"aspect\": 1.5,\n    \"size\": 2.5,\n}\nsel = {\"time\": slice(8, 25)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the keypoint positions over time.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "positions.sel(**sel).squeeze().plot.line(**plot_params)\nplt.subplots_adjust(right=0.85)  # Make space on the right for the legend\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Normalised keypoint positions over time\nNormalizing the pupil's position relative to the midpoint of the eye reduces\nthe impact of head movements or artefacts caused by camera movement. By\nsubtracting the position of the eye's midpoint, we effectively transform the\ndata into a moving coordinate system, with the eye's midpoint as the origin.\nIn the rest of the example, the normalised data will be used.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "eye_midpoint = positions.sel(keypoints=[\"eye-L\", \"eye-R\"]).mean(\"keypoints\")\npositions_norm = positions - eye_midpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We plot the x and y positions again, but now using the normalised data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "positions_norm.sel(**sel).squeeze().plot.line(**plot_params)\nplt.subplots_adjust(right=0.85)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pupil position over time\nTo look at pupil position\u2014and later also velocity\u2014over time, we use the\npupil centroid (in this case the midpoint between keypoints ``pupil-L`` and\n``pupil-R``). The keypoint ``pupil-C`` is assigned using\n``xarray.DataArray.assign_coords``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pupil_centroid = (\n    positions_norm.sel(keypoints=[\"pupil-L\", \"pupil-R\"])\n    .mean(\"keypoints\")\n    .assign_coords({\"keypoints\": \"pupil-C\"})\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The pupil centroid keypoint ``pupil-C`` is be added to the ``positions_norm``\nusing ``xarray.concat``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "positions_norm = xr.concat([positions_norm, pupil_centroid], dim=\"keypoints\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now the position of the pupil centroid ``pupil-C`` can be plotted.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "positions_norm.sel(keypoints=\"pupil-C\", **sel).squeeze().plot.line(\n    x=\"time\", hue=\"space\", row=\"lighting\", aspect=3.5, size=1.5\n)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pupil velocity over time\nIn these experiments, the mouse is being rotated clock- or anti-clock-wise,\ntriggering the vestibulo-ocular reflex. This reflex involves the\nvestibular system in the inner ear, that detects head motion and adjusts eye\nposition to maintain stable vision.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When the head turns beyond the range that the vestibulo-ocular reflex\ncan compensate for, a quick, ballistic eye movement is triggered to\nshift gaze to a new fixation point. These fast eye movements are seen in the\nprevious plot but become even more obvious when the velocity of the pupil\ncentroid is plotted. To do this, we use ``compute_velocity`` from the\n``movement.kinematics`` module to calculate the velocity of the eye\nmovements.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pupil_velocity = kin.compute_velocity(positions_norm.sel(keypoints=\"pupil-C\"))\npupil_velocity.name = \"pupil velocity\"\npupil_velocity.sel(**sel).squeeze().plot.line(\n    x=\"time\", hue=\"space\", row=\"lighting\", aspect=3.5, size=1.5\n)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The positive peaks correspond to rapid eye movements to the right, the\nnegative peaks correspond to rapid eye movements to the left.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pupil diameter\nHere we define the pupil diameter as the distance between the two pupil\nkeypoints. We use ``compute_pairwise_distances`` from ``movement.kinematics``\nto calculate the Euclidean distance between ``pupil-L`` and ``pupil-R``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pupil_diameter: xr.DataArray = kin.compute_pairwise_distances(\n    positions_norm, dim=\"keypoints\", pairs={\"pupil-L\": \"pupil-R\"}\n)\npupil_diameter.name = \"pupil diameter\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now the pupil diameter can be plotted.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pupil_diameter.plot.line(x=\"time\", hue=\"lighting\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The plot of the pupil diameter looks noisy. The very steep peaks are\nunlikely to represent real changes in the pupil size.\nIn fact, these steep peaks are probably caused by tracking errors\nduring blinking or squinting.\nBy looking at the distance between the two eye keypoints we can get an idea\nof whether (and when) the animal is blinking or squinting.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "distance_between_eye_keypoints: xr.DataArray = kin.compute_pairwise_distances(\n    positions_norm, dim=\"keypoints\", pairs={\"eye-L\": \"eye-R\"}\n)\ndistance_between_eye_keypoints.name = \"distance (eye-L - eye-R)\"\n\n# Combine the datasets into one DataArray\ncombined = xr.concat(\n    [distance_between_eye_keypoints, pupil_diameter], dim=\"variable\"\n)\ncombined = combined.assign_coords(\n    variable=[\"distance (eye-L - eye-R)\", \"pupil diameter\"]\n)\n\n# Plot the distance between the eye keypoints alongside the pupil diameter\ncombined.plot.line(\n    x=\"time\", row=\"lighting\", hue=\"variable\", figsize=(8, 4), add_legend=False\n)\nlabels = combined.coords[\"variable\"].values\nplt.legend(labels, loc=\"center\", bbox_to_anchor=(0.5, 1.4), ncol=2)\nplt.xlabel(\"time (s)\")\n[ax.set_ylabel(\"distance (pixels)\") for ax in plt.gcf().axes]\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We indeed see that the sharp peaks in pupil diameter correspond to abrupt\nchanges of distance between the two eye keypoints.\nCompared to fast eye movements and blinking, changes in pupil size are slow.\nFilters can be applied to reduce noise and make underlying trends\nin pupil diameter clearer.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Smooth pupil diameter\nA rolling mean (moving average) filter is used here to smooth the data by\naveraging a specified number of data points (``window_len``).\nWe achieve this by calling the :func:`movement.filtering.rolling_filter`\nfunction with the ``statistic=\"mean\"`` option.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "window_len = 80\nmean_filter = rolling_filter(\n    pupil_diameter, window=window_len, statistic=\"mean\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now the filtered pupil diameter can be plotted.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mean_filter.plot.line(x=\"time\", hue=\"lighting\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Instead of the mean, we could also use the median, which is the default\noption for the ``statistic`` argument, and should be more robust to outliers.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mdn_filter = rolling_filter(pupil_diameter, window_len, statistic=\"median\")\nmdn_filter.plot.line(x=\"time\", hue=\"lighting\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. seealso::\n  `sphx_glr_examples_smooth.py` example.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}